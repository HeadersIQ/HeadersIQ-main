{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69b9993d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Property: AboutPage.breadcrumb | Expected Types: ['BreadcrumbList', 'Text']\n",
      "2. Property: AboutPage.lastReviewed | Expected Types: Date\n",
      "3. Property: AboutPage.mainContentOfPage | Expected Types: WebPageElement\n",
      "4. Property: AboutPage.primaryImageOfPage | Expected Types: ImageObject\n",
      "5. Property: AboutPage.relatedLink | Expected Types: URL\n",
      "6. Property: AboutPage.reviewedBy | Expected Types: ['Organization', 'Person']\n",
      "7. Property: AboutPage.significantLink | Expected Types: URL\n",
      "8. Property: AboutPage.speakable | Expected Types: ['SpeakableSpecification', 'URL']\n",
      "9. Property: AboutPage.specialty | Expected Types: Specialty\n",
      "10. Property: AboutPage.about | Expected Types: Thing\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import csv\n",
    "from io import StringIO\n",
    "\n",
    "# Example file: AboutPage_propsToTypes.csv\n",
    "GITHUB_RAW_URL = \"https://raw.githubusercontent.com/wbsg-uni-mannheim/wdc-sotab/main/data/PropsToTypes/AboutPage_propsToTypes.csv\"\n",
    "\n",
    "response = requests.get(GITHUB_RAW_URL)\n",
    "response.raise_for_status()  # Raise an error for bad status\n",
    "\n",
    "csvfile = StringIO(response.text)\n",
    "reader = csv.DictReader(csvfile)\n",
    "\n",
    "# Get first 10 properties\n",
    "for i, row in enumerate(reader):\n",
    "    if i >= 10:\n",
    "        break\n",
    "    print(f\"{i+1}. Property: {row['property']} | Expected Types: {row['expected_types']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3bdd336",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Excel file created: AboutPage_properties.xlsx\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import csv\n",
    "import pandas as pd\n",
    "import ast\n",
    "\n",
    "# 1. Choose the file and base link\n",
    "type_name = \"AboutPage\"\n",
    "github_csv_url = f\"https://raw.githubusercontent.com/wbsg-uni-mannheim/wdc-sotab/main/data/PropsToTypes/{type_name}_propsToTypes.csv\"\n",
    "schema_link = f\"https://schema.org/{type_name}\"\n",
    "\n",
    "# 2. Download and parse the CSV\n",
    "response = requests.get(github_csv_url)\n",
    "response.raise_for_status()\n",
    "rows = list(csv.DictReader(response.text.splitlines()))\n",
    "\n",
    "# 3. Process and explode rows with multiple expected types\n",
    "output_rows = []\n",
    "for row in rows:\n",
    "    prop = row[\"property\"]\n",
    "    expected_types = row[\"expected_types\"]\n",
    "    try:\n",
    "        # Handle expected_types as a list (if present)\n",
    "        types = ast.literal_eval(expected_types) if expected_types.startswith(\"[\") else [expected_types]\n",
    "    except:\n",
    "        types = [expected_types]\n",
    "    for t in types:\n",
    "        t = t.strip().strip(\"'\").strip('\"')\n",
    "        output_rows.append({\n",
    "            \"schema_link\": schema_link,\n",
    "            \"property\": prop,\n",
    "            \"expected_type\": t\n",
    "        })\n",
    "\n",
    "# 4. Save to Excel\n",
    "df = pd.DataFrame(output_rows)\n",
    "excel_file = f\"{type_name}_properties.xlsx\"\n",
    "df.to_excel(excel_file, index=False)\n",
    "\n",
    "print(f\"Excel file created: {excel_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df3681bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV files found: ['AboutPage_propsToTypes.csv', 'Action_propsToTypes.csv', 'AdministrativeArea_propsToTypes.csv'] ...\n",
      "Excel file created: First3PropsToTypes.xlsx\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import ast\n",
    "from io import StringIO\n",
    "\n",
    "# GitHub API to list folder contents\n",
    "api_url = \"https://api.github.com/repos/wbsg-uni-mannheim/wdc-sotab/contents/data/PropsToTypes\"\n",
    "raw_prefix = \"https://raw.githubusercontent.com/wbsg-uni-mannheim/wdc-sotab/main/data/PropsToTypes/\"\n",
    "\n",
    "headers = {'User-Agent': 'Mozilla/5.0'}\n",
    "response = requests.get(api_url, headers=headers)\n",
    "files_json = response.json()\n",
    "\n",
    "# Get only CSV files\n",
    "csv_files = [f['name'] for f in files_json if f['name'].endswith('.csv')]\n",
    "print(\"CSV files found:\", csv_files[:3], \"...\")\n",
    "\n",
    "all_rows = []\n",
    "\n",
    "# For testing, just process first 3 CSVs\n",
    "for fname in csv_files[:3]:\n",
    "    type_name = fname.replace(\"_propsToTypes.csv\", \"\")\n",
    "    schema_link = f\"https://schema.org/{type_name}\"\n",
    "    raw_url = raw_prefix + fname\n",
    "    try:\n",
    "        r = requests.get(raw_url, headers=headers)\n",
    "        r.raise_for_status()\n",
    "        df = pd.read_csv(StringIO(r.text))\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to process {fname}: {e}\")\n",
    "        continue\n",
    "    for _, row in df.iterrows():\n",
    "        prop = row[\"property\"]\n",
    "        expected_types = str(row[\"expected_types\"])\n",
    "        try:\n",
    "            types = ast.literal_eval(expected_types) if expected_types.strip().startswith(\"[\") else [expected_types]\n",
    "        except Exception:\n",
    "            types = [expected_types]\n",
    "        for t in types:\n",
    "            t = str(t).strip().strip(\"'\").strip('\"')\n",
    "            all_rows.append({\n",
    "                \"schema_link\": f'=HYPERLINK(\"{schema_link}\", \"{type_name}\")',\n",
    "                \"property\": prop,\n",
    "                \"expected_type\": t\n",
    "            })\n",
    "\n",
    "if all_rows:\n",
    "    df_out = pd.DataFrame(all_rows)\n",
    "    df_out.to_excel(\"First3PropsToTypes.xlsx\", index=False)\n",
    "    print(\"Excel file created: First3PropsToTypes.xlsx\")\n",
    "else:\n",
    "    print(\"No data found!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6bc96c1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total CSV files found: 116\n",
      "Excel file created: AllPropsToTypes.xlsx\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import ast\n",
    "from io import StringIO\n",
    "\n",
    "# 1. Get all CSV file names from GitHub API\n",
    "api_url = \"https://api.github.com/repos/wbsg-uni-mannheim/wdc-sotab/contents/data/PropsToTypes\"\n",
    "raw_prefix = \"https://raw.githubusercontent.com/wbsg-uni-mannheim/wdc-sotab/main/data/PropsToTypes/\"\n",
    "\n",
    "headers = {'User-Agent': 'Mozilla/5.0'}\n",
    "response = requests.get(api_url, headers=headers)\n",
    "files_json = response.json()\n",
    "\n",
    "csv_files = [f['name'] for f in files_json if f['name'].endswith('.csv')]\n",
    "print(f\"Total CSV files found: {len(csv_files)}\")\n",
    "\n",
    "all_rows = []\n",
    "\n",
    "# 2. Process ALL CSV files\n",
    "for fname in csv_files:\n",
    "    type_name = fname.replace(\"_propsToTypes.csv\", \"\")\n",
    "    schema_link = f\"https://schema.org/{type_name}\"\n",
    "    raw_url = raw_prefix + fname\n",
    "    try:\n",
    "        r = requests.get(raw_url, headers=headers)\n",
    "        r.raise_for_status()\n",
    "        df = pd.read_csv(StringIO(r.text))\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to process {fname}: {e}\")\n",
    "        continue\n",
    "    for _, row in df.iterrows():\n",
    "        prop = row[\"property\"]\n",
    "        expected_types = str(row[\"expected_types\"])\n",
    "        # Explode lists like ['Person','Organization'] into separate lines\n",
    "        try:\n",
    "            types = ast.literal_eval(expected_types) if expected_types.strip().startswith(\"[\") else [expected_types]\n",
    "        except Exception:\n",
    "            types = [expected_types]\n",
    "        for t in types:\n",
    "            t = str(t).strip().strip(\"'\").strip('\"')\n",
    "            all_rows.append({\n",
    "                \"schema_link\": f'=HYPERLINK(\"{schema_link}\", \"{type_name}\")',\n",
    "                \"property\": prop,\n",
    "                \"expected_type\": t\n",
    "            })\n",
    "\n",
    "# 3. Write to Excel\n",
    "if all_rows:\n",
    "    df_out = pd.DataFrame(all_rows)\n",
    "    excel_file = \"AllPropsToTypes.xlsx\"\n",
    "    df_out.to_excel(excel_file, index=False)\n",
    "    print(f\"Excel file created: {excel_file}\")\n",
    "else:\n",
    "    print(\"No data found!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f546517c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Excel file created: AllPropsToTypes_noThingProps.xlsx\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "def get_direct_properties(type_name):\n",
    "    url = f\"https://schema.org/{type_name}\"\n",
    "    headers = {'User-Agent': 'Mozilla/5.0'}\n",
    "    resp = requests.get(url, headers=headers)\n",
    "    soup = BeautifulSoup(resp.text, \"html.parser\")\n",
    "\n",
    "    tables = soup.find_all('table')\n",
    "    results = []\n",
    "\n",
    "    for table in tables:\n",
    "        # Find the section header just before the table\n",
    "        prev = table.find_previous(['h4', 'h3', 'h2', 'h5'])\n",
    "        if prev and prev.text.strip() == f\"Properties from {type_name}\":\n",
    "            # Go through rows\n",
    "            for row in table.find_all('tr'):\n",
    "                cells = row.find_all(['th', 'td'])\n",
    "                if len(cells) == 2:  # Skip header\n",
    "                    prop = cells[0].get_text(strip=True)\n",
    "                    exptype = cells[1].get_text(strip=True)\n",
    "                    results.append({'type': type_name, 'property': prop, 'expected_type': exptype})\n",
    "    return results\n",
    "\n",
    "# Example for AboutPage\n",
    "props = get_direct_properties(\"AboutPage\")\n",
    "df = pd.DataFrame(props)\n",
    "print(df)\n",
    "df.to_excel(\"AboutPage_direct_properties.xlsx\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82f8569b",
   "metadata": {},
   "source": [
    "Going all the way "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7cd34a06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Direct properties for AboutPage:\n",
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n",
      "Direct properties for WebPage:\n",
      "       type            property           expected_type\n",
      "0   WebPage          breadcrumb          BreadcrumbList\n",
      "1   WebPage          breadcrumb                    Text\n",
      "2   WebPage        lastReviewed                    Date\n",
      "3   WebPage   mainContentOfPage          WebPageElement\n",
      "4   WebPage  primaryImageOfPage             ImageObject\n",
      "5   WebPage         relatedLink                     URL\n",
      "6   WebPage          reviewedBy            Organization\n",
      "7   WebPage          reviewedBy                  Person\n",
      "8   WebPage     significantLink                     URL\n",
      "9   WebPage           speakable  SpeakableSpecification\n",
      "10  WebPage           speakable                     URL\n",
      "11  WebPage           specialty               Specialty\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "def get_direct_properties(type_name):\n",
    "    url = f\"https://schema.org/{type_name}\"\n",
    "    headers = {'User-Agent': 'Mozilla/5.0'}\n",
    "    resp = requests.get(url, headers=headers)\n",
    "    soup = BeautifulSoup(resp.text, \"html.parser\")\n",
    "    results = []\n",
    "    table = soup.find(\"table\", class_=\"definition-table\")\n",
    "    if not table:\n",
    "        return results\n",
    "    rows = table.find_all(\"tr\")\n",
    "    in_correct_section = False\n",
    "    for row in rows:\n",
    "        # Section header row\n",
    "        if \"supertype\" in row.get(\"class\", []):\n",
    "            th = row.find(\"th\", class_=\"supertype-name\")\n",
    "            if th and th.find(\"a\") and th.find(\"a\").get_text(strip=True) == type_name:\n",
    "                in_correct_section = True\n",
    "            else:\n",
    "                in_correct_section = False\n",
    "            continue\n",
    "        # Data row (must have property and type and description)\n",
    "        if in_correct_section and row.find(\"th\", class_=\"prop-nam\"):\n",
    "            prop = row.find(\"th\", class_=\"prop-nam\").get_text(strip=True)\n",
    "            type_cell = row.find(\"td\", class_=\"prop-ect\")\n",
    "            # Type can have multiple <a> or text, sometimes separated by <br/>\n",
    "            if type_cell:\n",
    "                # This reliably gets the human-readable, joined text (with or, |, etc)\n",
    "                types_text = type_cell.get_text(separator=\"|\", strip=True)\n",
    "                types = [t.strip() for t in types_text.replace(\"or\", \"|\").split(\"|\") if t.strip()]\n",
    "            else:\n",
    "                types = [\"\"]\n",
    "            for exptype in types:\n",
    "                results.append({\n",
    "                    \"type\": type_name,\n",
    "                    \"property\": prop,\n",
    "                    \"expected_type\": exptype\n",
    "                })\n",
    "    return results\n",
    "\n",
    "# Test for WebPage and AboutPage\n",
    "for t in [\"AboutPage\", \"WebPage\"]:\n",
    "    props = get_direct_properties(t)\n",
    "    df = pd.DataFrame(props)\n",
    "    print(f\"Direct properties for {t}:\")\n",
    "    print(df)\n",
    "    df.to_excel(f\"{t}_direct_properties.xlsx\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd920e07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/116] AboutPage... No direct properties.\n",
      "[2/116] Action... 22 direct properties found.\n",
      "[3/116] AdministrativeArea... No direct properties.\n",
      "[4/116] AggregateRating... 3 direct properties found.\n",
      "[5/116] Airport... 2 direct properties found.\n",
      "[6/116] Audience... 2 direct properties found.\n",
      "[7/116] AudioObject... 4 direct properties found.\n",
      "[8/116] Book... 7 direct properties found.\n",
      "[9/116] BookFormatType... No direct properties.\n",
      "[10/116] Boolean... No direct properties.\n",
      "[11/116] Brand... 5 direct properties found.\n",
      "[12/116] CategoryCode... 4 direct properties found.\n",
      "[13/116] City... No direct properties.\n",
      "[14/116] Clip... 17 direct properties found.\n",
      "[15/116] CollegeOrUniversity... No direct properties.\n",
      "[16/116] Comment... 7 direct properties found.\n",
      "[17/116] ContactPoint... 14 direct properties found.\n",
      "[18/116] Continent... No direct properties.\n",
      "[19/116] Country... No direct properties.\n",
      "[20/116] CreativeWork... 184 direct properties found.\n",
      "[21/116] CreativeWorkSeason... 16 direct properties found.\n",
      "[22/116] CreativeWorkSeries... 5 direct properties found.\n",
      "[23/116] Dataset... 15 direct properties found.\n",
      "[24/116] Date... No direct properties.\n",
      "[25/116] DateTime... No direct properties.\n",
      "[26/116] DefinedTerm... 3 direct properties found.\n",
      "[27/116] Demand... 59 direct properties found.\n",
      "[28/116] Distance... No direct properties.\n",
      "[29/116] Duration... No direct properties.\n",
      "[30/116] EducationalOccupationalCredential... 12 direct properties found.\n",
      "[31/116] EducationalOrganization... 1 direct properties found.\n",
      "[32/116] Event... 62 direct properties found.\n",
      "[33/116] EventAttendanceModeEnumeration... No direct properties.\n",
      "[34/116] EventStatusType... No direct properties.\n",
      "[35/116] GenderType... No direct properties.\n",
      "[36/116] GeoCoordinates... 11 direct properties found.\n",
      "[37/116] GeoShape... 11 direct properties found.\n",
      "[38/116] GovernmentOrganization... No direct properties.\n",
      "[39/116] Hospital... 7 direct properties found.\n",
      "[40/116] Hotel... No direct properties.\n",
      "[41/116] HowToSection... No direct properties.\n",
      "[42/116] HowToStep... No direct properties.\n",
      "[43/116] HowToTool... No direct properties.\n",
      "[44/116] ImageObject... 6 direct properties found.\n",
      "[45/116] Integer... No direct properties.\n",
      "[46/116] InteractionCounter... 12 direct properties found.\n",
      "[47/116] ItemList... 7 direct properties found.\n",
      "[48/116] JobPosting... 55 direct properties found.\n",
      "[49/116] LakeBodyOfWater... No direct properties.\n",
      "[50/116] LandmarksOrHistoricalBuildings... No direct properties.\n",
      "[51/116] Language... No direct properties.\n",
      "[52/116] Library... No direct properties.\n",
      "[53/116] LoanOrCredit... 12 direct properties found.\n",
      "[54/116] LocalBusiness... 4 direct properties found.\n",
      "[55/116] LocationFeatureSpecification... 5 direct properties found.\n",
      "[56/116] Map... 2 direct properties found.\n",
      "[57/116] MedicalProcedure... 9 direct properties found.\n",
      "[58/116] MedicalTest... 6 direct properties found.\n",
      "[59/116] MedicalTherapy... 4 direct properties found.\n",
      "[60/116] Menu... 2 direct properties found.\n",
      "[61/116] MonetaryAmount... 11 direct properties found.\n",
      "[62/116] MonetaryAmountDistribution... 1 direct properties found.\n",
      "[63/116] Mountain... No direct properties.\n",
      "[64/116] Movie... 15 direct properties found.\n",
      "[65/116] Museum... No direct properties.\n",
      "[66/116] MusicAlbum... 5 direct properties found.\n",
      "[67/116] MusicGroup... 6 direct properties found.\n",
      "[68/116] MusicRecording... 8 direct properties found.\n",
      "[69/116] Number... No direct properties.\n",
      "[70/116] NutritionInformation... 12 direct properties found.\n",
      "[71/116] OccupationalExperienceRequirements... 1 direct properties found.\n",
      "[72/116] Offer... 87 direct properties found.\n",
      "[73/116] OfferCatalog... No direct properties.\n",
      "[74/116] OfferItemCondition... No direct properties.\n",
      "[75/116] OpeningHoursSpecification... 7 direct properties found.\n",
      "[76/116] Organization... 109 direct properties found.\n",
      "[77/116] OwnershipInfo... 6 direct properties found.\n",
      "[78/116] Painting... No direct properties.\n",
      "[79/116] Park... No direct properties.\n",
      "[80/116] PaymentMethod... 1 direct properties found.\n",
      "[81/116] Person... 86 direct properties found.\n",
      "[82/116] Photograph... No direct properties.\n",
      "[83/116] PhysicalActivityCategory... No direct properties.\n",
      "[84/116] Place... 61 direct properties found.\n",
      "[85/116] PostalAddress... 8 direct properties found.\n",
      "[86/116] PriceSpecification... 15 direct properties found.\n",
      "[87/116] Product... 90 direct properties found.\n",
      "[88/116] ProductGroup... 4 direct properties found.\n",
      "[89/116] ProductModel... 4 direct properties found.\n",
      "[90/116] ProgramMembership... 8 direct properties found.\n",
      "[91/116] PropertyValue... 27 direct properties found.\n",
      "[92/116] PublicationEvent... 3 direct properties found.\n",
      "[93/116] QuantitativeValue... 18 direct properties found.\n",
      "[94/116] RadioStation... No direct properties.\n",
      "[95/116] Rating... 10 direct properties found.\n",
      "[96/116] Recipe... 14 direct properties found.\n",
      "[97/116] Restaurant... No direct properties.\n",
      "[98/116] RestrictedDiet... No direct properties.\n",
      "[99/116] Review... 15 direct properties found.\n",
      "[100/116] RiverBodyOfWater... No direct properties.\n",
      "[101/116] School... No direct properties.\n",
      "[102/116] Service... 40 direct properties found.\n",
      "[103/116] ShoppingCenter... No direct properties.\n",
      "[104/116] SizeSpecification... 9 direct properties found.\n",
      "[105/116] SkiResort... No direct properties.\n",
      "[106/116] SportsEvent... 12 direct properties found.\n",
      "[107/116] SportsTeam... 4 direct properties found.\n",
      "[108/116] StadiumOrArena... No direct properties.\n",
      "[109/116] TVEpisode... 5 direct properties found.\n",
      "[110/116] TelevisionStation... No direct properties.\n",
      "[111/116] Text... No direct properties.\n",
      "[112/116] Thing... 21 direct properties found.\n",
      "[113/116] Time... No direct properties.\n",
      "[114/116] URL... No direct properties.\n",
      "[115/116] VideoObject... 12 direct properties found.\n",
      "[116/116] VirtualLocation... No direct properties.\n",
      "All done! Output in AllSchemaOrgDirectProperties_withLinks.xlsx\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "def get_direct_properties(type_name):\n",
    "    url = f\"https://schema.org/{type_name}\"\n",
    "    headers = {'User-Agent': 'Mozilla/5.0'}\n",
    "    resp = requests.get(url, headers=headers)\n",
    "    soup = BeautifulSoup(resp.text, \"html.parser\")\n",
    "    results = []\n",
    "    table = soup.find(\"table\", class_=\"definition-table\")\n",
    "    if not table:\n",
    "        return results\n",
    "    rows = table.find_all(\"tr\")\n",
    "    in_correct_section = False\n",
    "    for row in rows:\n",
    "        # Section header row\n",
    "        if \"supertype\" in row.get(\"class\", []):\n",
    "            th = row.find(\"th\", class_=\"supertype-name\")\n",
    "            if th and th.find(\"a\") and th.find(\"a\").get_text(strip=True) == type_name:\n",
    "                in_correct_section = True\n",
    "            else:\n",
    "                in_correct_section = False\n",
    "            continue\n",
    "        # Data row (must have property and type)\n",
    "        if in_correct_section and row.find(\"th\", class_=\"prop-nam\"):\n",
    "            prop_cell = row.find(\"th\", class_=\"prop-nam\")\n",
    "            # The property name and link\n",
    "            prop = prop_cell.get_text(strip=True)\n",
    "            prop_link_tag = prop_cell.find(\"a\")\n",
    "            if prop_link_tag and prop_link_tag.get(\"href\"):\n",
    "                prop_url = \"https://schema.org\" + prop_link_tag.get(\"href\")\n",
    "            else:\n",
    "                prop_url = f\"https://schema.org/{prop}\"\n",
    "            type_cell = row.find(\"td\", class_=\"prop-ect\")\n",
    "            if type_cell:\n",
    "                types_text = type_cell.get_text(separator=\"|\", strip=True)\n",
    "                types = [t.strip() for t in types_text.replace(\"or\", \"|\").split(\"|\") if t.strip()]\n",
    "            else:\n",
    "                types = [\"\"]\n",
    "            for exptype in types:\n",
    "                results.append({\n",
    "                    \"property_link\": f'=HYPERLINK(\"{prop_url}\", \"{prop}\")',\n",
    "                    \"type_property\": f\"{type_name}.{prop}\",\n",
    "                    \"expected_type\": exptype\n",
    "                })\n",
    "    return results\n",
    "\n",
    "# 1. Get all types from GitHub\n",
    "api_url = \"https://api.github.com/repos/wbsg-uni-mannheim/wdc-sotab/contents/data/PropsToTypes\"\n",
    "headers = {'User-Agent': 'Mozilla/5.0'}\n",
    "files_json = requests.get(api_url, headers=headers).json()\n",
    "type_names = sorted({f['name'].replace(\"_propsToTypes.csv\", \"\") for f in files_json if f['name'].endswith('.csv')})\n",
    "\n",
    "# 2. Loop over all types, scrape direct properties\n",
    "all_results = []\n",
    "for i, t in enumerate(type_names):\n",
    "    print(f\"[{i+1}/{len(type_names)}] {t}...\", end=\"\")\n",
    "    props = get_direct_properties(t)\n",
    "    if props:\n",
    "        all_results.extend(props)\n",
    "        print(f\" {len(props)} direct properties found.\")\n",
    "    else:\n",
    "        print(\" No direct properties.\")\n",
    "    time.sleep(0.15)  # Be nice to schema.org\n",
    "\n",
    "# 3. Save all results in one Excel\n",
    "df = pd.DataFrame(all_results)\n",
    "excel_file = \"AllSchemaOrgDirectProperties_withLinks.xlsx\"\n",
    "df.to_excel(excel_file, index=False)\n",
    "print(f\"All done! Output in {excel_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "944e6e04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/116] AboutPage... No direct properties.\n",
      "[2/116] Action... 22 direct properties found.\n",
      "[3/116] AdministrativeArea... No direct properties.\n",
      "[4/116] AggregateRating... 3 direct properties found.\n",
      "[5/116] Airport... 2 direct properties found.\n",
      "[6/116] Audience... 2 direct properties found.\n",
      "[7/116] AudioObject... 4 direct properties found.\n",
      "[8/116] Book... 6 direct properties found.\n",
      "[9/116] BookFormatType... No direct properties.\n",
      "[10/116] Boolean... No direct properties.\n",
      "[11/116] Brand... 5 direct properties found.\n",
      "[12/116] CategoryCode... 3 direct properties found.\n",
      "[13/116] City... No direct properties.\n",
      "[14/116] Clip... 14 direct properties found.\n",
      "[15/116] CollegeOrUniversity... No direct properties.\n",
      "[16/116] Comment... 5 direct properties found.\n",
      "[17/116] ContactPoint... 14 direct properties found.\n",
      "[18/116] Continent... No direct properties.\n",
      "[19/116] Country... No direct properties.\n",
      "[20/116] CreativeWork... 169 direct properties found.\n",
      "[21/116] CreativeWorkSeason... 14 direct properties found.\n",
      "[22/116] CreativeWorkSeries... 5 direct properties found.\n",
      "[23/116] Dataset... 15 direct properties found.\n",
      "[24/116] Date... No direct properties.\n",
      "[25/116] DateTime... No direct properties.\n",
      "[26/116] DefinedTerm... 3 direct properties found.\n",
      "[27/116] Demand... 58 direct properties found.\n",
      "[28/116] Distance... No direct properties.\n",
      "[29/116] Duration... No direct properties.\n",
      "[30/116] EducationalOccupationalCredential... 12 direct properties found.\n",
      "[31/116] EducationalOrganization... 1 direct properties found.\n",
      "[32/116] Event... 58 direct properties found.\n",
      "[33/116] EventAttendanceModeEnumeration... No direct properties.\n",
      "[34/116] EventStatusType... No direct properties.\n",
      "[35/116] GenderType... No direct properties.\n",
      "[36/116] GeoCoordinates... 11 direct properties found.\n",
      "[37/116] GeoShape... 11 direct properties found.\n",
      "[38/116] GovernmentOrganization... No direct properties.\n",
      "[39/116] Hospital... 6 direct properties found.\n",
      "[40/116] Hotel... No direct properties.\n",
      "[41/116] HowToSection... No direct properties.\n",
      "[42/116] HowToStep... No direct properties.\n",
      "[43/116] HowToTool... No direct properties.\n",
      "[44/116] ImageObject... 6 direct properties found.\n",
      "[45/116] Integer... No direct properties.\n",
      "[46/116] InteractionCounter... 12 direct properties found.\n",
      "[47/116] ItemList... 7 direct properties found.\n",
      "[48/116] JobPosting... 54 direct properties found.\n",
      "[49/116] LakeBodyOfWater... No direct properties.\n",
      "[50/116] LandmarksOrHistoricalBuildings... No direct properties.\n",
      "[51/116] Language... No direct properties.\n",
      "[52/116] Library... No direct properties.\n",
      "[53/116] LoanOrCredit... 12 direct properties found.\n",
      "[54/116] LocalBusiness... 4 direct properties found.\n",
      "[55/116] LocationFeatureSpecification... 5 direct properties found.\n",
      "[56/116] Map... 1 direct properties found.\n",
      "[57/116] MedicalProcedure... 9 direct properties found.\n",
      "[58/116] MedicalTest... 6 direct properties found.\n",
      "[59/116] MedicalTherapy... 4 direct properties found.\n",
      "[60/116] Menu... 2 direct properties found.\n",
      "[61/116] MonetaryAmount... 11 direct properties found.\n",
      "[62/116] MonetaryAmountDistribution... 1 direct properties found.\n",
      "[63/116] Mountain... No direct properties.\n",
      "[64/116] Movie... 14 direct properties found.\n",
      "[65/116] Museum... No direct properties.\n",
      "[66/116] MusicAlbum... 5 direct properties found.\n",
      "[67/116] MusicGroup... 5 direct properties found.\n",
      "[68/116] MusicRecording... 8 direct properties found.\n",
      "[69/116] Number... No direct properties.\n",
      "[70/116] NutritionInformation... 12 direct properties found.\n",
      "[71/116] OccupationalExperienceRequirements... 1 direct properties found.\n",
      "[72/116] Offer... 84 direct properties found.\n",
      "[73/116] OfferCatalog... No direct properties.\n",
      "[74/116] OfferItemCondition... No direct properties.\n",
      "[75/116] OpeningHoursSpecification... 7 direct properties found.\n",
      "[76/116] Organization... 102 direct properties found.\n",
      "[77/116] OwnershipInfo... 6 direct properties found.\n",
      "[78/116] Painting... No direct properties.\n",
      "[79/116] Park... No direct properties.\n",
      "[80/116] PaymentMethod... 1 direct properties found.\n",
      "[81/116] Person... 85 direct properties found.\n",
      "[82/116] Photograph... No direct properties.\n",
      "[83/116] PhysicalActivityCategory... No direct properties.\n",
      "[84/116] Place... 60 direct properties found.\n",
      "[85/116] PostalAddress... 8 direct properties found.\n",
      "[86/116] PriceSpecification... 15 direct properties found.\n",
      "[87/116] Product... 88 direct properties found.\n",
      "[88/116] ProductGroup... 4 direct properties found.\n",
      "[89/116] ProductModel... 4 direct properties found.\n",
      "[90/116] ProgramMembership... 8 direct properties found.\n",
      "[91/116] PropertyValue... 27 direct properties found.\n",
      "[92/116] PublicationEvent... 3 direct properties found.\n",
      "[93/116] QuantitativeValue... 18 direct properties found.\n",
      "[94/116] RadioStation... No direct properties.\n",
      "[95/116] Rating... 10 direct properties found.\n",
      "[96/116] Recipe... 12 direct properties found.\n",
      "[97/116] Restaurant... No direct properties.\n",
      "[98/116] RestrictedDiet... No direct properties.\n",
      "[99/116] Review... 15 direct properties found.\n",
      "[100/116] RiverBodyOfWater... No direct properties.\n",
      "[101/116] School... No direct properties.\n",
      "[102/116] Service... 38 direct properties found.\n",
      "[103/116] ShoppingCenter... No direct properties.\n",
      "[104/116] SizeSpecification... 9 direct properties found.\n",
      "[105/116] SkiResort... No direct properties.\n",
      "[106/116] SportsEvent... 9 direct properties found.\n",
      "[107/116] SportsTeam... 4 direct properties found.\n",
      "[108/116] StadiumOrArena... No direct properties.\n",
      "[109/116] TVEpisode... 5 direct properties found.\n",
      "[110/116] TelevisionStation... No direct properties.\n",
      "[111/116] Text... No direct properties.\n",
      "[112/116] Thing... 19 direct properties found.\n",
      "[113/116] Time... No direct properties.\n",
      "[114/116] URL... No direct properties.\n",
      "[115/116] VideoObject... 11 direct properties found.\n",
      "[116/116] VirtualLocation... No direct properties.\n"
     ]
    },
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: 'AllSchemaOrgDirectProperties_withLinks.xlsx'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 83\u001b[0m\n\u001b[0;32m     81\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(all_results)\n\u001b[0;32m     82\u001b[0m excel_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAllSchemaOrgDirectProperties_withLinks.xlsx\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 83\u001b[0m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_excel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexcel_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     84\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAll done! Output in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexcel_file\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\util\\_decorators.py:333\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    327\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    328\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    329\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    330\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    331\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    332\u001b[0m     )\n\u001b[1;32m--> 333\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\generic.py:2417\u001b[0m, in \u001b[0;36mNDFrame.to_excel\u001b[1;34m(self, excel_writer, sheet_name, na_rep, float_format, columns, header, index, index_label, startrow, startcol, engine, merge_cells, inf_rep, freeze_panes, storage_options, engine_kwargs)\u001b[0m\n\u001b[0;32m   2404\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mformats\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexcel\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ExcelFormatter\n\u001b[0;32m   2406\u001b[0m formatter \u001b[38;5;241m=\u001b[39m ExcelFormatter(\n\u001b[0;32m   2407\u001b[0m     df,\n\u001b[0;32m   2408\u001b[0m     na_rep\u001b[38;5;241m=\u001b[39mna_rep,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2415\u001b[0m     inf_rep\u001b[38;5;241m=\u001b[39minf_rep,\n\u001b[0;32m   2416\u001b[0m )\n\u001b[1;32m-> 2417\u001b[0m \u001b[43mformatter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2418\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexcel_writer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2419\u001b[0m \u001b[43m    \u001b[49m\u001b[43msheet_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msheet_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2420\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstartrow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstartrow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2421\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstartcol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstartcol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2422\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfreeze_panes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfreeze_panes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2423\u001b[0m \u001b[43m    \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2424\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2425\u001b[0m \u001b[43m    \u001b[49m\u001b[43mengine_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2426\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\io\\formats\\excel.py:943\u001b[0m, in \u001b[0;36mExcelFormatter.write\u001b[1;34m(self, writer, sheet_name, startrow, startcol, freeze_panes, engine, storage_options, engine_kwargs)\u001b[0m\n\u001b[0;32m    941\u001b[0m     need_save \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    942\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 943\u001b[0m     writer \u001b[38;5;241m=\u001b[39m \u001b[43mExcelWriter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    944\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwriter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    945\u001b[0m \u001b[43m        \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    946\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    947\u001b[0m \u001b[43m        \u001b[49m\u001b[43mengine_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    948\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    949\u001b[0m     need_save \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    951\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\io\\excel\\_openpyxl.py:61\u001b[0m, in \u001b[0;36mOpenpyxlWriter.__init__\u001b[1;34m(self, path, engine, date_format, datetime_format, mode, storage_options, if_sheet_exists, engine_kwargs, **kwargs)\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mopenpyxl\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mworkbook\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Workbook\n\u001b[0;32m     59\u001b[0m engine_kwargs \u001b[38;5;241m=\u001b[39m combine_kwargs(engine_kwargs, kwargs)\n\u001b[1;32m---> 61\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m     62\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     63\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     64\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     65\u001b[0m \u001b[43m    \u001b[49m\u001b[43mif_sheet_exists\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mif_sheet_exists\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[43m    \u001b[49m\u001b[43mengine_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     67\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;66;03m# ExcelWriter replaced \"a\" by \"r+\" to allow us to first read the excel file from\u001b[39;00m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;66;03m# the file and later write to it\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr+\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mode:  \u001b[38;5;66;03m# Load from existing workbook\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\io\\excel\\_base.py:1246\u001b[0m, in \u001b[0;36mExcelWriter.__init__\u001b[1;34m(self, path, engine, date_format, datetime_format, mode, storage_options, if_sheet_exists, engine_kwargs)\u001b[0m\n\u001b[0;32m   1242\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handles \u001b[38;5;241m=\u001b[39m IOHandles(\n\u001b[0;32m   1243\u001b[0m     cast(IO[\u001b[38;5;28mbytes\u001b[39m], path), compression\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mNone\u001b[39;00m}\n\u001b[0;32m   1244\u001b[0m )\n\u001b[0;32m   1245\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path, ExcelWriter):\n\u001b[1;32m-> 1246\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1247\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[0;32m   1248\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1249\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cur_sheet \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1251\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m date_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\io\\common.py:882\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    874\u001b[0m             handle,\n\u001b[0;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    879\u001b[0m         )\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m--> 882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    883\u001b[0m     handles\u001b[38;5;241m.\u001b[39mappend(handle)\n\u001b[0;32m    885\u001b[0m \u001b[38;5;66;03m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: 'AllSchemaOrgDirectProperties_withLinks.xlsx'"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "def extract_expected_types(type_cell):\n",
    "    types = [a.get_text(strip=True) for a in type_cell.find_all(\"a\")]\n",
    "    last_text = type_cell.get_text(\" \", strip=True)\n",
    "    if types:\n",
    "        last_type = types[-1]\n",
    "        if last_type in last_text:\n",
    "            after_last = last_text.split(last_type, 1)[-1]\n",
    "            # Get plain text types after the last linked type\n",
    "            extras = [s.strip() for s in after_last.split(\"or\") if s.strip()]\n",
    "            for extra in extras:\n",
    "                if extra and extra not in types:\n",
    "                    types.append(extra)\n",
    "    else:\n",
    "        types = [s.strip() for s in last_text.split(\"or\") if s.strip()]\n",
    "    return types\n",
    "\n",
    "def get_direct_properties(type_name):\n",
    "    url = f\"https://schema.org/{type_name}\"\n",
    "    headers = {'User-Agent': 'Mozilla/5.0'}\n",
    "    resp = requests.get(url, headers=headers)\n",
    "    soup = BeautifulSoup(resp.text, \"html.parser\")\n",
    "    results = []\n",
    "    table = soup.find(\"table\", class_=\"definition-table\")\n",
    "    if not table:\n",
    "        return results\n",
    "    rows = table.find_all(\"tr\")\n",
    "    in_correct_section = False\n",
    "    for row in rows:\n",
    "        if \"supertype\" in row.get(\"class\", []):\n",
    "            th = row.find(\"th\", class_=\"supertype-name\")\n",
    "            if th and th.find(\"a\") and th.find(\"a\").get_text(strip=True) == type_name:\n",
    "                in_correct_section = True\n",
    "            else:\n",
    "                in_correct_section = False\n",
    "            continue\n",
    "        if in_correct_section and row.find(\"th\", class_=\"prop-nam\"):\n",
    "            prop_cell = row.find(\"th\", class_=\"prop-nam\")\n",
    "            prop = prop_cell.get_text(strip=True)\n",
    "            prop_link_tag = prop_cell.find(\"a\")\n",
    "            if prop_link_tag and prop_link_tag.get(\"href\"):\n",
    "                prop_url = \"https://schema.org\" + prop_link_tag.get(\"href\")\n",
    "            else:\n",
    "                prop_url = f\"https://schema.org/{prop}\"\n",
    "            type_cell = row.find(\"td\", class_=\"prop-ect\")\n",
    "            if type_cell:\n",
    "                types = extract_expected_types(type_cell)\n",
    "            else:\n",
    "                types = [\"\"]\n",
    "            for exptype in types:\n",
    "                results.append({\n",
    "                    \"property_link\": f'=HYPERLINK(\"{prop_url}\", \"{prop}\")',\n",
    "                    \"type_property\": f\"{type_name}.{prop}\",\n",
    "                    \"expected_type\": exptype\n",
    "                })\n",
    "    return results\n",
    "\n",
    "# 1. Get all types from GitHub\n",
    "api_url = \"https://api.github.com/repos/wbsg-uni-mannheim/wdc-sotab/contents/data/PropsToTypes\"\n",
    "headers = {'User-Agent': 'Mozilla/5.0'}\n",
    "files_json = requests.get(api_url, headers=headers).json()\n",
    "type_names = sorted({f['name'].replace(\"_propsToTypes.csv\", \"\") for f in files_json if f['name'].endswith('.csv')})\n",
    "\n",
    "# 2. Loop over all types, scrape direct properties\n",
    "all_results = []\n",
    "for i, t in enumerate(type_names):\n",
    "    print(f\"[{i+1}/{len(type_names)}] {t}...\", end=\"\")\n",
    "    props = get_direct_properties(t)\n",
    "    if props:\n",
    "        all_results.extend(props)\n",
    "        print(f\" {len(props)} direct properties found.\")\n",
    "    else:\n",
    "        print(\" No direct properties.\")\n",
    "    time.sleep(0.15)  # Be nice to schema.org\n",
    "\n",
    "# 3. Save all results in one Excel\n",
    "df = pd.DataFrame(all_results)\n",
    "excel_file = \"AllSchemaOrgDirectProperties_withLinks.xlsx\"\n",
    "df.to_excel(excel_file, index=False)\n",
    "print(f\"All done! Output in {excel_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96a4b2cd",
   "metadata": {},
   "source": [
    "Frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eed82f25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 Schema.org types by property count:\n",
      "    property_link  count\n",
      "0      areaServed     20\n",
      "1  valueReference     16\n",
      "2        location     16\n",
      "3        keywords     15\n",
      "4        category     15\n",
      "5    validThrough     14\n",
      "6     itemOffered     14\n",
      "7       validFrom     12\n",
      "8           value     12\n",
      "9           actor     10\n",
      "\n",
      "Top 10 expected types by count:\n",
      "       expected_type  count\n",
      "0               Text    311\n",
      "1                URL     85\n",
      "2             Person     76\n",
      "3       Organization     59\n",
      "4               Date     39\n",
      "5              Place     39\n",
      "6           DateTime     38\n",
      "7  QuantitativeValue     36\n",
      "8        DefinedTerm     33\n",
      "9             Number     32\n",
      "Frequency distributions saved to PropsToTypes_Frequency.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load your Excel file\n",
    "df = pd.read_excel(\"AllSchemaOrgDirectProperties_withLinks.xlsx\")\n",
    "\n",
    "# Frequency of schema.org types (first column)\n",
    "type_counts = df['property_link'].value_counts().reset_index()\n",
    "type_counts.columns = ['property_link', 'count']\n",
    "\n",
    "# Frequency of expected types (third column)\n",
    "expected_counts = df['expected_type'].value_counts().reset_index()\n",
    "expected_counts.columns = ['expected_type', 'count']\n",
    "\n",
    "# Display top 10 of each (optional)\n",
    "print(\"Top 10 Schema.org types by property count:\")\n",
    "print(type_counts.head(10))\n",
    "\n",
    "print(\"\\nTop 10 expected types by count:\")\n",
    "print(expected_counts.head(10))\n",
    "\n",
    "# Save results to Excel\n",
    "with pd.ExcelWriter(\"PropsToTypes_Frequency.xlsx\") as writer:\n",
    "    type_counts.to_excel(writer, sheet_name='Type_Frequency', index=False)\n",
    "    expected_counts.to_excel(writer, sheet_name='ExpectedType_Frequency', index=False)\n",
    "\n",
    "print(\"Frequency distributions saved to PropsToTypes_Frequency.xlsx\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
